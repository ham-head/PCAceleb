{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#necessary libs\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm, trange\n#multiprocessing to speed up things\nfrom multiprocessing import Pool\n#Image Processing Libs\nfrom IPython.display import display, Image\nimport cv2 as cv","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-28T07:16:53.988424Z","iopub.execute_input":"2022-04-28T07:16:53.988851Z","iopub.status.idle":"2022-04-28T07:16:53.999134Z","shell.execute_reply.started":"2022-04-28T07:16:53.988809Z","shell.execute_reply":"2022-04-28T07:16:53.998488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for inspecting data\nPATH = '../input/celebrities-100k/100k/100k/'\nImage(PATH + '168202.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.020153Z","iopub.execute_input":"2022-04-28T07:16:54.021109Z","iopub.status.idle":"2022-04-28T07:16:54.041422Z","shell.execute_reply.started":"2022-04-28T07:16:54.021066Z","shell.execute_reply":"2022-04-28T07:16:54.0407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"code","source":"#keras imports\nfrom tensorflow.keras import Model, Sequential\nfrom tensorflow.keras.layers import Input, Flatten, Reshape, Conv2DTranspose \nfrom tensorflow.keras.layers import Embedding, BatchNormalization, ReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence, plot_model\nfrom tensorflow.python.keras import backend\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.049668Z","iopub.execute_input":"2022-04-28T07:16:54.049902Z","iopub.status.idle":"2022-04-28T07:16:54.057464Z","shell.execute_reply.started":"2022-04-28T07:16:54.049871Z","shell.execute_reply":"2022-04-28T07:16:54.05675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 128\nNUM_EPOCHS = 125\nLR = 0.001\nNUM_SAMPLES = len(os.listdir(PATH))\nNUM_SAMPLES","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.080303Z","iopub.execute_input":"2022-04-28T07:16:54.080538Z","iopub.status.idle":"2022-04-28T07:16:54.152158Z","shell.execute_reply.started":"2022-04-28T07:16:54.080509Z","shell.execute_reply":"2022-04-28T07:16:54.15152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Embedding(NUM_SAMPLES, 32, input_length=1))\nmodel.add(Flatten(name='pre_encoder'))\nmodel.add(Reshape((32, 1, 1), name='encoder'))\n\nmodel.add(Conv2DTranspose(128, 4, strides=(1, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(256, 4, strides=(1, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(512, 4, strides=(1, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(256, 4, strides=(1, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(128, 4, strides=(1, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(128, 4, strides=(2, 2), padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(ReLU())\n\nmodel.add(Conv2DTranspose(3, 4, strides=2, padding=\"same\", activation=\"sigmoid\"))\n\nmodel.compile(optimizer=Adam(learning_rate=LR), loss='mse')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.156754Z","iopub.execute_input":"2022-04-28T07:16:54.159469Z","iopub.status.idle":"2022-04-28T07:16:54.659222Z","shell.execute_reply.started":"2022-04-28T07:16:54.159433Z","shell.execute_reply":"2022-04-28T07:16:54.658373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.660333Z","iopub.execute_input":"2022-04-28T07:16:54.660577Z","iopub.status.idle":"2022-04-28T07:16:54.677722Z","shell.execute_reply.started":"2022-04-28T07:16:54.660545Z","shell.execute_reply":"2022-04-28T07:16:54.675373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='model.png', show_shapes=True)\ndisplay(Image('model.png'))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.679677Z","iopub.execute_input":"2022-04-28T07:16:54.679969Z","iopub.status.idle":"2022-04-28T07:16:54.98736Z","shell.execute_reply.started":"2022-04-28T07:16:54.67991Z","shell.execute_reply":"2022-04-28T07:16:54.985924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING + DATA GENERATION","metadata":{}},{"cell_type":"code","source":"X = np.expand_dims(np.arange(NUM_SAMPLES), axis=1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.989074Z","iopub.execute_input":"2022-04-28T07:16:54.989994Z","iopub.status.idle":"2022-04-28T07:16:54.996632Z","shell.execute_reply.started":"2022-04-28T07:16:54.989935Z","shell.execute_reply":"2022-04-28T07:16:54.995918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_image(x, fname):\n    img = x * 255.0\n    img = cv.cvtColor(img.astype(np.float32), cv.COLOR_RGB2BGR)\n    cv.imwrite(fname, img)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:54.998085Z","iopub.execute_input":"2022-04-28T07:16:54.998728Z","iopub.status.idle":"2022-04-28T07:16:55.005407Z","shell.execute_reply.started":"2022-04-28T07:16:54.998693Z","shell.execute_reply":"2022-04-28T07:16:55.004496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keras Data Generator Class, can't fit 100k pics in memory at once :(\nclass DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, n_samples=NUM_SAMPLES, batch_size=BATCH_SIZE, dim=(128, 128), n_channels=3, \n                 path=PATH, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = np.arange(n_samples)\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.path = path\n        self.imgs = os.listdir(PATH)\n        self.currepoch = 0\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n        # save images so we can check progress over epochs\n        y_faces = model.predict(X[:8], batch_size=8)\n        save_image(cv.hconcat(y_faces), f\"epoch{self.currepoch:03}.jpg\")\n        \n        self.currepoch += 1\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        Y = np.empty((self.batch_size, *self.dim, self.n_channels))\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            img = cv.imread(PATH + self.imgs[ID])\n            img = cv.cvtColor(img, cv.COLOR_BGR2RGB) / 255.0\n            Y[i,] = img\n\n        return np.expand_dims(list_IDs_temp, axis=1), Y","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:55.007051Z","iopub.execute_input":"2022-04-28T07:16:55.007583Z","iopub.status.idle":"2022-04-28T07:16:55.027825Z","shell.execute_reply.started":"2022-04-28T07:16:55.007547Z","shell.execute_reply":"2022-04-28T07:16:55.027043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPU Available: \", tf.test.is_gpu_available())\nprint(\"TF Version: \", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:55.028826Z","iopub.execute_input":"2022-04-28T07:16:55.029085Z","iopub.status.idle":"2022-04-28T07:16:55.046412Z","shell.execute_reply.started":"2022-04-28T07:16:55.029059Z","shell.execute_reply":"2022-04-28T07:16:55.044395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = DataGenerator(batch_size=BATCH_SIZE) \n\nearly_stopping = EarlyStopping(\n    monitor='loss', \n    patience=5\n)\n\nhistory = model.fit(datagen, epochs=NUM_EPOCHS, callbacks=[early_stopping], verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:16:55.050484Z","iopub.execute_input":"2022-04-28T07:16:55.05118Z","iopub.status.idle":"2022-04-28T07:17:32.120816Z","shell.execute_reply.started":"2022-04-28T07:16:55.051077Z","shell.execute_reply":"2022-04-28T07:17:32.119517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.122065Z","iopub.status.idle":"2022-04-28T07:17:32.126532Z","shell.execute_reply.started":"2022-04-28T07:17:32.126335Z","shell.execute_reply":"2022-04-28T07:17:32.126358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoder Model","metadata":{}},{"cell_type":"code","source":"encoder = Model(inputs=model.input,\n                outputs=model.get_layer('pre_encoder').output)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.127968Z","iopub.status.idle":"2022-04-28T07:17:32.129265Z","shell.execute_reply.started":"2022-04-28T07:17:32.129082Z","shell.execute_reply":"2022-04-28T07:17:32.129102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_enc = encoder.predict(X, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.130852Z","iopub.status.idle":"2022-04-28T07:17:32.131525Z","shell.execute_reply.started":"2022-04-28T07:17:32.131287Z","shell.execute_reply":"2022-04-28T07:17:32.131312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_mean = np.mean(x_enc, axis=0)\nx_stds = np.std(x_enc, axis=0)\nx_cov = np.cov((x_enc - x_mean).T)\ne, v = np.linalg.eig(x_cov)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.132828Z","iopub.status.idle":"2022-04-28T07:17:32.133494Z","shell.execute_reply.started":"2022-04-28T07:17:32.133258Z","shell.execute_reply":"2022-04-28T07:17:32.133282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.keras import backend\n\ntf.compat.v1.disable_eager_execution() #this will allow us to get to intermediate layers\n\n#this is a really ugly work around\n#I want the performance gains from eager execution but cant use function with it\n#so make sure this is run in order\nloaded = load_model('model.h5') #built without eager execution\n\n## TODO MAKE A DECODER that always works\ntry:\n    decoder = backend.function([loaded.get_layer('encoder').input, backend.symbolic_learning_phase()],\n                      [loaded.layers[-1].output])\nexcept:\n    print(\"decoder failed to be built.\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.13489Z","iopub.status.idle":"2022-04-28T07:17:32.135571Z","shell.execute_reply.started":"2022-04-28T07:17:32.135333Z","shell.execute_reply":"2022-04-28T07:17:32.135357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_vecs = np.random.normal(0.0, 1.0, (8, 32))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.137202Z","iopub.status.idle":"2022-04-28T07:17:32.13786Z","shell.execute_reply.started":"2022-04-28T07:17:32.137612Z","shell.execute_reply":"2022-04-28T07:17:32.137636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vecs = x_mean + np.dot(v, (rand_vecs * (e ** 0.5).T).T\ntry:\n    y_faces = decoder([x_vecs, 0])[0]  \nexcept:    \n    y_faces = np.array([])","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.139199Z","iopub.status.idle":"2022-04-28T07:17:32.140023Z","shell.execute_reply.started":"2022-04-28T07:17:32.13971Z","shell.execute_reply":"2022-04-28T07:17:32.139738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(y_faces.shape[0]):\n    save_image(y_faces[i], f'rand{i}.jpg')\n    display(Image(f'rand{i}.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.141547Z","iopub.status.idle":"2022-04-28T07:17:32.142205Z","shell.execute_reply.started":"2022-04-28T07:17:32.14196Z","shell.execute_reply":"2022-04-28T07:17:32.141984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n#to use with js\nwith open(\"means.json\", 'w') as f:\n    json.dump(x_mean.tolist(), f)\n\nwith open(\"stds.json\", 'w') as f:\n    json.dump(x_stds.tolist(), f)\n\nwith open(\"evals.json\", 'w') as f:\n    json.dump(e.tolist(), f)\n\nwith open(\"evecs.json\", 'w') as f:\n    json.dump(v.tolist(), f)\n    \n# np.save('means.npy', x_mean)\n# np.save('stds.npy', x_stds)\n# np.save('evals.npy', e)\n# np.save('evecs.npy', v)","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.143899Z","iopub.status.idle":"2022-04-28T07:17:32.144575Z","shell.execute_reply.started":"2022-04-28T07:17:32.144332Z","shell.execute_reply":"2022-04-28T07:17:32.144356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflowjs --user","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.146059Z","iopub.status.idle":"2022-04-28T07:17:32.146702Z","shell.execute_reply.started":"2022-04-28T07:17:32.146456Z","shell.execute_reply":"2022-04-28T07:17:32.146482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert to tf.js format so we can use w/ web app\nimport tensorflowjs as tfjs\ntfjs.converters.save_keras_model(model, \"FaceModel\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.148045Z","iopub.status.idle":"2022-04-28T07:17:32.148787Z","shell.execute_reply.started":"2022-04-28T07:17:32.148509Z","shell.execute_reply":"2022-04-28T07:17:32.148537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\ntry:\n    for i in range(1, NUM_EPOCHS, 5):\n        images.append(cv.imread(f\"epoch{i:03}.jpg\"))\n    save_image(cv.v_concat(images), \"epochs.jpg\")\n    display(Image(\"epochs.jpg\"))\nexcept:\n    print(\"Collage image failed ;/\")","metadata":{"execution":{"iopub.status.busy":"2022-04-28T07:17:32.150071Z","iopub.status.idle":"2022-04-28T07:17:32.150706Z","shell.execute_reply.started":"2022-04-28T07:17:32.150461Z","shell.execute_reply":"2022-04-28T07:17:32.150485Z"},"trusted":true},"execution_count":null,"outputs":[]}]}